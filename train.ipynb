{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.概要"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EfficientNetが以下のような3種類の画像を分類できるように訓練します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./img/train_2022-05-29-17-06-08.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "モデルの訓練には主に以下のものが必要です。  \n",
    "  \n",
    "\n",
    "・画像の前処理をするもの  \n",
    "・Dataset(データをまとめるクラス)  \n",
    "・DataLoader(データをモデルに入力するもの)  \n",
    "・モデル  \n",
    "・損失関数  \n",
    "・オプティマイザー(モデルのパラメータの調整方法)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.ライブラリのインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "from torchvision import transforms\n",
    "import json\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "#from efficientnet_pytorch import EfficientNet\n",
    "\n",
    "import tensorboardX as tbx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.乱数のシード（再現性の担保）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seed 数字はなんでもいい\n",
    "torch.manual_seed(999)\n",
    "random.seed(999)\n",
    "np.random.seed(999)\n",
    "seed = 999\n",
    "\n",
    "#Disabling the benchmark by CUDA convolution operation(GPUを使うときの再現性の担保) (https://pytorch.org/docs/stable/notes/randomness.html)\n",
    "torch.backends.cudnn.benchmark = False \n",
    "torch.backends.cudnn.determinstic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "動作確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0457])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#0~1の乱数を出力\n",
    "torch.rand(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.辞書argsのロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ここにpathなどを記述\n",
    "json_file = open('args.json','r')\n",
    "args = json.load(json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "動作確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'efficientnet-b4'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args[\"model_name\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "※データセットのRBG値の平均(mean),標準偏差(std)の求め方は、『PyTorch実践入門』の208ページなどをご覧ください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![画像が表示されていないきは、vscodeの「ファイル」⇒「フォルダを開く」でこのファイルが入っているフォルダを開いてみてください](./img/train_2022-02-10-14-55-27.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.デバイスを呼び出す関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_GPU():\n",
    "    \"\"\"\n",
    "    使用するデバイスを出力する関数\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    device : object\n",
    "        GPUが使えるなら'cuda:0',使えないなら'cpu'を返す\n",
    "    \"\"\"\n",
    "    print(\"Check GPU\")\n",
    "    print(torch.cuda.is_available())\n",
    "    print(\"-----\")\n",
    "    if torch.cuda.is_available():\n",
    "        d_type = \"cuda:0\"\n",
    "    else:\n",
    "        d_type = \"cpu\"\n",
    "    device = torch.device(d_type)\n",
    "    return device "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "動作確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check GPU\n",
      "False\n",
      "-----\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = check_GPU()\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.画像の前処理クラス"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageTransform():\n",
    "    \"\"\"\n",
    "    画像の前処理クラス。\n",
    "    リサイズ → テンソル化 → 標準化\n",
    "    訓練時だけ、データオーギュメンテーション(DA)ができるように、train,validで分けて書いた\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    resize : int\n",
    "        画像のリサイズの値\n",
    "    mean : (R, G, B)\n",
    "        データセットのRGB値の各平均値\n",
    "    std : (R, G, B)\n",
    "        データセットのRGB値の各標準偏差\n",
    "    \"\"\"\n",
    "    # 初期化メソッド(特殊メソッド)\n",
    "    def __init__(self, resize, mean, std):\n",
    "        self.data_transform = {\n",
    "            'train': transforms.Compose([\n",
    "            transforms.Resize((resize,resize)),  \n",
    "            transforms.ToTensor(),  \n",
    "            transforms.Normalize(mean, std)  \n",
    "            ]),\n",
    "            'valid': transforms.Compose([\n",
    "            transforms.Resize((resize,resize)), \n",
    "            transforms.ToTensor(),  \n",
    "            transforms.Normalize(mean, std)  \n",
    "            ]),\n",
    "        }\n",
    "\n",
    "    #引数なしで呼ばれたときの挙動を定義(特殊メソッド)\n",
    "    def __call__(self, img, phase):\n",
    "        return self.data_transform[phase](img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.Datasets, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeatDataset(data.Dataset):\n",
    "    \"\"\"\n",
    "    画像のデータセットクラス。\n",
    "    Pytorch Dataset class を継承\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    file_list : list\n",
    "        画像のpath_list\n",
    "    label_list : list\n",
    "        ラベルのリスト\n",
    "    transform : object\n",
    "        class ImageTransform()\n",
    "    phase : str\n",
    "        'train' or 'valid'\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, file_list, label_list, transform, phase):\n",
    "        self.file_list = file_list\n",
    "        self.label_list = label_list\n",
    "        self.transform = transform  \n",
    "        self.phase = phase  \n",
    "\n",
    "    #このクラスの画像枚数を定義。\n",
    "    def __len__(self):\n",
    "        return len(self.file_list) \n",
    "\n",
    "    #このクラスに角括弧でアクセスした時の挙動を定義\n",
    "    def __getitem__(self, index):\n",
    "        # 画像をロード\n",
    "        img_path = self.file_list[index]\n",
    "        img = Image.open(img_path)  \n",
    "        # 前処理\n",
    "        img_transformed = self.transform(\n",
    "            img, self.phase)  # torch.Size([3, 224, 224])\n",
    "\n",
    "        #label\n",
    "        label = self.label_list[index]\n",
    "        #Tensorに変換\n",
    "        label = torch.tensor(label)         \n",
    "\n",
    "        return img_transformed , label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_path_list(image_root_path, mode): \n",
    "    \"\"\"\n",
    "    画像をクラスごとに集める関数\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    image_root_path : path\n",
    "        画像のroot_path. \n",
    "    mode : str\n",
    "        'class0' or 'class1' or 'class2\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    path_list : list\n",
    "        画像のpath_list\n",
    "    label_list : list\n",
    "        0 or 1 or 2\n",
    "    \"\"\"\n",
    "\n",
    "    path_list = glob.glob(os.path.join(image_root_path, mode ,'*.tif')) #画像path\n",
    "\n",
    "    if mode=='class0':\n",
    "        label = 0\n",
    "    elif mode=='class1':\n",
    "        label = 1\n",
    "    elif mode=='class2':\n",
    "        label = 2\n",
    "\n",
    "    label_list = [label for _ in range(len(path_list))]\n",
    "    \"\"\"これと同じ意味\n",
    "    label_list = []\n",
    "    for _ in range(len(path_list)):\n",
    "        label_list.append(label)\"\"\"\n",
    "\n",
    "    return path_list, label_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.NetWork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def efficientnet(model_name):\n",
    "    \"\"\"\n",
    "    efficientNetを持ってくる関数\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model_name : str\n",
    "        efficientnet-b4\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    model : object\n",
    "        訓練済efficientnetを出力\n",
    "    \"\"\"\n",
    "    model = EfficientNet.from_pretrained(model_name)\n",
    "    #modelの最終層の出力を3に変更する。\n",
    "    model._fc  = nn.Linear(in_features=1792, out_features=3, bias=True)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "動作確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 3, 380, 380])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = torch.randn((8,3,380,380))\n",
    "input.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0083,  0.0367, -0.0092],\n",
       "        [ 0.0588, -0.1134, -0.0585],\n",
       "        [ 0.1589,  0.1101, -0.0817],\n",
       "        [ 0.0284, -0.0097,  0.0696],\n",
       "        [-0.0711,  0.0835,  0.1356],\n",
       "        [-0.0330,  0.0514,  0.0783],\n",
       "        [ 0.0547, -0.2173,  0.1230],\n",
       "        [ 0.1484, -0.0296,  0.0045]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = efficientnet(args['model_name'])\n",
    "output = model(input)\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.損失関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#クロスエントロピー誤差関数\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![画像が表示されていないきは、vscodeの「ファイル」⇒「フォルダを開く」でこのファイルが入っているフォルダを開いてみてください](./img/train_2022-02-09-15-50-48.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "動作確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1000, 0.8000, 0.1000]])\n",
      "tensor([2])\n"
     ]
    }
   ],
   "source": [
    "y = torch.tensor([0.1,0.8,0.1]).unsqueeze(0)\n",
    "t = torch.tensor(2).unsqueeze(0)\n",
    "print(y)\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.3897)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion(y,t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.オプティマイザー"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = efficientnet(args['model_name'])\n",
    "\n",
    "#optimizer\n",
    "opt = torch.optim.Adam(model.parameters()) # model.parameters():モデルのパラメータ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "玉の転がし方を決める役割のイメージ？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![画像が表示されていないきは、vscodeの「ファイル」⇒「フォルダを開く」でこのファイルが入っているフォルダを開いてみてください](./img/train_2022-02-10-08-42-51.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloaders_dict, device, opt, criterion, writer, fold, save_root_path, me, le ):\n",
    "    \n",
    "    #ネットワークがある程度固定であれば、高速化\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "    print(\"\\nStarting training\")\n",
    "    for epoch in range(0, me+1):\n",
    "        print('Epoch {}/{} fold{}'.format(epoch, me, fold))\n",
    "        print('-------------')\n",
    "\n",
    "        # epochごとの学習と検証のループ\n",
    "        for phase in ['train', 'valid']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # モデルを訓練モードに\n",
    "            else:\n",
    "                model.eval()   # モデルを検証モードに\n",
    "\n",
    "            epoch_loss = 0.0  # epochの損失和                \n",
    "            correct = 0 #正解数\n",
    "            total = 0 #データ数\n",
    "\n",
    "            #未訓練時の性能評価\n",
    "            if (epoch == 0 and phase=='train'):\n",
    "                continue\n",
    "            \n",
    "            # データローダーからミニバッチを取り出すループ。args['batch_size']枚ごと取り出す\n",
    "            for inputs,labels in tqdm(dataloaders_dict[phase]):\n",
    "\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # optimizerを初期化。\n",
    "                opt.zero_grad()\n",
    "\n",
    "                # 順伝搬（forward）計算。\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels)  # 損失を計算。\n",
    "                    prediction = torch.argmax(outputs, dim=1)\n",
    "\n",
    "                    # 訓練時はバックプロパゲーション\n",
    "                    if phase == 'train':\n",
    "                        loss.backward() \n",
    "                        opt.step()\n",
    "\n",
    "                # 損失の計算\n",
    "                if phase == 'train':\n",
    "                    epoch_loss += loss.item()*inputs.size(0)/4\n",
    "                elif phase == 'valid':\n",
    "                    epoch_loss += loss.item()*inputs.size(0)\n",
    "\n",
    "                total += labels.shape[0] #データ数\n",
    "                correct += int((prediction == labels).sum()) #正解数\n",
    "\n",
    "            #accuracy\n",
    "            accuracy = correct/total\n",
    "\n",
    "            #tensorboardに出力\n",
    "            if phase == 'train':\n",
    "                writer.add_scalar(f'train_epoch_loss_fold{fold}', epoch_loss, epoch) #(グラフ名, y座標, x座標)\n",
    "                writer.add_scalar(f'train_epoch_accuracy_fold{fold}', accuracy, epoch)                \n",
    "            elif phase == 'valid':\n",
    "                writer.add_scalar(f'valid_epoch_loss_fold{fold}', epoch_loss, epoch)\n",
    "                writer.add_scalar(f'valid_epoch_accuracy_fold{fold}', accuracy, epoch)                  \n",
    "\n",
    "            # epochごとのloss,accuracyを表示\n",
    "            if epoch % le == 0:\n",
    "                print(f'phase:{phase}')\n",
    "                print(\"epoch = %4d   loss = %0.4f  accuracy = %0.4f\" %(epoch, epoch_loss, accuracy))\n",
    "\n",
    "        #epochごとに重みを保存\n",
    "        if epoch % 1 ==0:\n",
    "            save_path = os.path.join(save_root_path, 'model_weight', f'fold{fold}_epoch={epoch}.pth')\n",
    "            torch.save(model.state_dict(), save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.クロスバリデーション"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![画像が表示されていないきは、vscodeの「ファイル」⇒「フォルダを開く」でこのファイルが入っているフォルダを開いてみてください](./img/train_2022-02-09-16-39-13.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross validation 各Foldごとでラベルは均等にわけられる\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(args = args):\n",
    "    #GPU\n",
    "    device = check_GPU()\n",
    "\n",
    "    #画像の前処理クラス\n",
    "    transform = ImageTransform(args['resize'], args['mean'], args['std'])\n",
    "        \n",
    "    os.makedirs(os.path.join(args['save_root_path'], 'model_weight'), exist_ok=True) #重みファイルの保存\n",
    "\n",
    "    #画像pathを集める\n",
    "    path0,label0 = image_path_list(args['image_root_path'], mode='class0')\n",
    "    path1, label1 = image_path_list(args['image_root_path'], mode='class1')\n",
    "    path2, label2 = image_path_list(args['image_root_path'], mode='class2')\n",
    "\n",
    "    #すべてのパス,ラベルをまとめる\n",
    "    path = path0 + path1 + path2\n",
    "    label = label0 + label1 + label2\n",
    "\n",
    "    #criterion\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "    # cross validation\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "    \n",
    "    #logger\n",
    "    writer = tbx.SummaryWriter()\n",
    "\n",
    "    for fold , (train_idx, valid_idx) in enumerate(skf.split(path,label)): #loop Fold\n",
    "        train_path = [path[i] for i in train_idx]\n",
    "        valid_path = [path[i] for i in valid_idx]\n",
    "        train_label = [label[i] for i in train_idx] \n",
    "        valid_label = [label[i] for i in valid_idx]\n",
    "\n",
    "        #Dataset\n",
    "        train_dataset  = MeatDataset(train_path,train_label,transform,phase='train') \n",
    "        valid_dataset = MeatDataset(valid_path,valid_label,transform,phase='valid')\n",
    "\n",
    "        #DataLoder\n",
    "        train_dataloader = torch.utils.data.DataLoader(\n",
    "        train_dataset,batch_size=args['batch_size'],shuffle=True\n",
    "        )\n",
    "        valid_dataloader = torch.utils.data.DataLoader(\n",
    "        valid_dataset,batch_size=1,shuffle=False\n",
    "        )                  \n",
    "\n",
    "        # 辞書型変数にまとめる\n",
    "        dataloaders_dict = {\"train\": train_dataloader, \"valid\": valid_dataloader}        \n",
    "\n",
    "        #Network\n",
    "        model = efficientnet(args['model_name'])\n",
    "        model.to(device)\n",
    "\n",
    "        #optimizer\n",
    "        opt = torch.optim.Adam(model.parameters())\n",
    "\n",
    "        #train\n",
    "        train(model, dataloaders_dict, device, opt, criterion, writer, fold, args['save_root_path'], args['max_epoch'], args['log_every'])\n",
    "\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "※ TensorBoardで学習結果を確認するには、コマンド  \n",
    "tensorboard --logdir ’runsフォルダのパス’  \n",
    "と入力して、http://localhost:6006/ にアクセス"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0d8107a35fa094ff3ab363002b6c8185da584e870773dee388fcab323c6b799d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
